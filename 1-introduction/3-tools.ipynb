{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling, i.e. using Tools\n",
    "\n",
    "[tools openai tutorial](https://platform.openai.com/docs/guides/function-calling)\n",
    "\n",
    "A tool can be seen as a fucntion that the model can use/invoke.<br>\n",
    "Natrually if the modle wants to use a tool in the answer must be present:\n",
    "- the tool name\n",
    "- the formatted ouput to fit the paramters of the tool/function\n",
    "\n",
    "**Attention**: not all model supports tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from pprint import pprint\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': '2025-03-06T10:15',\n",
       " 'interval': 900,\n",
       " 'temperature_2m': 9.0,\n",
       " 'wind_speed_10m': 18.3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Define the tool (function) that we want to call\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"This is a publically available API that returns the weather for a given location.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n",
    "    )\n",
    "    data = response.json()\n",
    "    return data[\"current\"]\n",
    "\n",
    "get_weather(37.7749, -122.4194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# Define schemas for tools\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# schema which \n",
    "#   - informs the model what it does \n",
    "#   - what input arguments it expects\n",
    "\n",
    "tools = [ # each dict is a tool\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather\", #function name\n",
    "            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "                # NB netter is the description, bettwe would be the use of the model of this tool\n",
    "            \"parameters\": { # JSON schema defining the function's input arguments\n",
    "                \"type\": \"object\", # function expects an object (i.e., a dictionary) as input.\n",
    "                \"properties\": {\n",
    "                    \"latitude\": {\"type\": \"number\"},\n",
    "                    \"longitude\": {\"type\": \"number\"},\n",
    "                },\n",
    "                \"required\": [\"latitude\", \"longitude\"], # both latitude and longitude are mandatory.\n",
    "                \"additionalProperties\": False, # FORCE: No extra parameters are allowed\n",
    "            },\n",
    "            \"strict\": True, # The model wonâ€™t generate extra fields or accept unexpected input.\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Call model with get_weather tool defined\n",
    "\n",
    "The model will recevive as always an input/prompt.\n",
    "\n",
    "It will reason and output if it wants to:\n",
    "- give an asnwer\n",
    "- call a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: this is conversation history\n",
    "# this is the beginning, as long as the model calls new tools and thinks NEW messages will be added\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\", # role = specifies who is speaking \n",
    "        \"content\": \"You are a helpful weather assistant.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"What's the weather like in Paris today?\"\n",
    "    },\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama3.1\",\n",
    "    messages=messages,\n",
    "    tools=tools, # ATTNETION: tool passed\n",
    ")\n",
    "\n",
    "# in completion there will be the answer of the model, it can choose between\n",
    "# 1) give an asnwer\n",
    "# 2) call a tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Check what the model decided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'choices': [{'finish_reason': 'tool_calls',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'audio': None,\n",
      "                          'content': '',\n",
      "                          'function_call': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': [{'function': {'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
      "                                                       'name': 'get_weather'},\n",
      "                                          'id': 'call_z95ioyx6',\n",
      "                                          'index': 0,\n",
      "                                          'type': 'function'}]}}],\n",
      " 'created': 1741256279,\n",
      " 'id': 'chatcmpl-802',\n",
      " 'model': 'llama3.1',\n",
      " 'object': 'chat.completion',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': 'fp_ollama',\n",
      " 'usage': {'completion_tokens': 29,\n",
      "           'completion_tokens_details': None,\n",
      "           'prompt_tokens': 184,\n",
      "           'prompt_tokens_details': None,\n",
      "           'total_tokens': 213}}\n",
      "\n",
      "\n",
      "[ChatCompletionMessageToolCall(id='call_z95ioyx6', function=Function(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', name='get_weather'), type='function', index=0)]\n",
      "\n",
      "\n",
      "ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z95ioyx6', function=Function(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', name='get_weather'), type='function', index=0)])\n"
     ]
    }
   ],
   "source": [
    "pprint(completion.model_dump()) #This prints out the full model response.\n",
    "# in the completion there will be the answer of the model.\n",
    "# Within the fields:\n",
    "# - finish_reason --> what was the esit of the call\n",
    "# - tool_call\n",
    "#     - name of function\n",
    "#     - par to use\n",
    "\n",
    "# more specific for tool\n",
    "print(\"\\n\")\n",
    "pprint(completion.choices[0].message.tool_calls)\n",
    "print(\"\\n\")\n",
    "pprint(completion.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Define call-tools function\n",
    "\n",
    "The model has only answered with the tool and parameters that it wants to use, it hasn't executed any call --> we must do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fucntion that depending of model output calls differt tools\n",
    "def call_function(name, args):\n",
    "    \"\"\"\n",
    "    name: name fo the tool/function to call\n",
    "    arsg: arguemts to pass\n",
    "    \"\"\"\n",
    "    if name == \"get_weather\":\n",
    "        return get_weather(**args) # **args(unpacking the dictionary into keyword arguments).\n",
    "    if name == \"get_gene\":\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Use the tools\n",
    "\n",
    "For each tool that the model wants to use, invoke the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather\n",
      "{'latitude': 48.8566, 'longitude': 2.3522}\n",
      "[{'content': 'You are a helpful weather assistant.', 'role': 'system'},\n",
      " {'content': \"What's the weather like in Paris today?\", 'role': 'user'},\n",
      " ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z95ioyx6', function=Function(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', name='get_weather'), type='function', index=0)])]\n",
      "{\"time\": \"2025-03-06T10:15\", \"interval\": 900, \"temperature_2m\": 10.7, \"wind_speed_10m\": 9.9}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in completion.choices[0].message.tool_calls: # for each tool call\n",
    "\n",
    "    name = tool_call.function.name # extract the name of the tool\n",
    "    args = json.loads(tool_call.function.arguments) # extarct the pars\n",
    "\n",
    "    # appne to message history the answer of the llm\n",
    "    messages.append(completion.choices[0].message)\n",
    "\n",
    "    print(name)\n",
    "    print(args)\n",
    "    pprint(messages)\n",
    "\n",
    "    # call the fucntion that calls single tools/fucntions\n",
    "    result = call_function(name, args)\n",
    "    print(json.dumps(result)) #converts (or serializes) a Python object into a JSON-formatted STRINGs\n",
    "\n",
    "    # append result of tool to message history\n",
    "    # NB The result is formatted, marking it with \"role\": \"tool\" and including the tool call ID\n",
    "    messages.append(\n",
    "        {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"content\": json.dumps(result)}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful weather assistant.'},\n",
       " {'role': 'user', 'content': \"What's the weather like in Paris today?\"},\n",
       " ChatCompletionMessage(content='', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z95ioyx6', function=Function(arguments='{\"latitude\":48.8566,\"longitude\":2.3522}', name='get_weather'), type='function', index=0)]),\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_z95ioyx6',\n",
       "  'content': '{\"time\": \"2025-03-06T10:15\", \"interval\": 900, \"temperature_2m\": 10.7, \"wind_speed_10m\": 9.9}'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Rerun the model with new info\n",
    "\n",
    "Just to be sure, force the ouput of the model to be structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted output:  temperature=10.7 response=\"It's currently 10.7Â°C (49.3Â°F) in Paris, with a gentle breeze. The wind speed is approximately 9.9 mph.\"\n",
      "temp Â°C:  10.7\n",
      "It's currently 10.7Â°C (49.3Â°F) in Paris, with a gentle breeze. The wind speed is approximately 9.9 mph.\n"
     ]
    }
   ],
   "source": [
    "# Defien pydantic class for stuctred respsonse\n",
    "class WeatherResponse(BaseModel):\n",
    "    temperature: float = Field(\n",
    "            # Field: It does not change the data type, but adds metadata like descriptions, default values, constraints, etc.\n",
    "        description=\"The current temperature in celsius for the given location.\",\n",
    "        #default=float(\"nan\"), # default value\n",
    "        gt=-100, lt=100 #bounds\n",
    "    )\n",
    "    response: str = Field(\n",
    "        description=\"A natural language response to the user's question.\"\n",
    "    )\n",
    "\n",
    "# Run the model again\n",
    "completion_2 = client.beta.chat.completions.parse(\n",
    "    model=\"llama3.1\",\n",
    "    messages=messages, # ATTNETION: histry is upadated\n",
    "    tools=tools,\n",
    "    response_format=WeatherResponse,\n",
    ")\n",
    "\n",
    "#Check model response\n",
    "final_response = completion_2.choices[0].message.parsed\n",
    "print(\"formatted output: \", final_response)\n",
    "print(\"temp Â°C: \", final_response.temperature)\n",
    "print(final_response.response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
