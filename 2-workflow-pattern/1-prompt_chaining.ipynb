{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining\n",
    "\n",
    "It is a specific pattern that to build an AI agent, i.e. how user prompt, llm reasoning and tools responses are linked otgether.\n",
    "\n",
    "Prompt chaining decomposes a task into a sequence of steps, where each LLM call processes the output of the previous one. You can add programmatic checks (see \"gateâ€ in the diagram below) on any intermediate steps to ensure that the process is still on track.\n",
    "\n",
    "![assets/prompt-chaning.png][assets/prompt-chaning.pngdef]\n",
    "\n",
    "Tutorial: given as prompt a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging configuration\n",
    "\n",
    "logging.basicConfig( #logging module, which is used to record events and messages generated by a program\n",
    "    level=logging.INFO, #  only messages of level INFO and higher (INFO, WARNING, ERROR, CRITICAL) will be logged.\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\", # specifies the format of the log messages\n",
    "        # time-log level-message\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\", #format of the timestamp in the log messages\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilalize ollama api\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    ")\n",
    "\n",
    "MODEL = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strucred data with pydantic\n",
    "\n",
    "class EventExtraction(BaseModel):\n",
    "    \"\"\"First LLM call: Extract basic event information\"\"\"\n",
    "\n",
    "    description: str = Field(description=\"Raw description of the event\")\n",
    "    is_calendar_event: bool = Field(description=\"Whether this text describes a calendar event\")\n",
    "    confidence_score: float = Field(description=\"Confidence score between 0 and 1\")\n",
    "\n",
    "\n",
    "class EventDetails(BaseModel):\n",
    "    \"\"\"Second LLM call: Parse specific event details\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the event\")\n",
    "    date: str = Field(description=\"Date and time of the event. Use ISO 8601 to format this value.\")\n",
    "    duration_minutes: int = Field(description=\"Expected duration in minutes\")\n",
    "    participants: list[str] = Field(description=\"List of participants\")\n",
    "\n",
    "\n",
    "class EventConfirmation(BaseModel):\n",
    "    \"\"\"Third LLM call: Generate confirmation message\"\"\"\n",
    "\n",
    "    confirmation_message: str = Field(description=\"Natural language confirmation message\")\n",
    "    calendar_link: Optional[str] = Field(description=\"Generated calendar link if applicable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Define the functions\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_event_info(user_input: str) -> EventExtraction:\n",
    "    \"\"\"First LLM call to determine if input is a calendar event\"\"\"\n",
    "    logger.info(\"Starting event extraction analysis\")\n",
    "    logger.debug(f\"Input text: {user_input}\")\n",
    "\n",
    "    today = datetime.now()\n",
    "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{date_context} Analyze if the text describes a calendar event.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        response_format=EventExtraction,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\n",
    "        f\"Extraction complete - Is calendar event: {result.is_calendar_event}, Confidence: {result.confidence_score:.2f}\"\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_event_details(description: str) -> EventDetails:\n",
    "    \"\"\"Second LLM call to extract specific event details\"\"\"\n",
    "    logger.info(\"Starting event details parsing\")\n",
    "\n",
    "    today = datetime.now()\n",
    "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{date_context} Extract detailed event information. When dates reference 'next Tuesday' or similar relative dates, use this current date as reference.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        response_format=EventDetails,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\n",
    "        f\"Parsed event details - Name: {result.name}, Date: {result.date}, Duration: {result.duration_minutes}min\"\n",
    "    )\n",
    "    logger.debug(f\"Participants: {', '.join(result.participants)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_confirmation(event_details: EventDetails) -> EventConfirmation:\n",
    "    \"\"\"Third LLM call to generate a confirmation message\"\"\"\n",
    "    logger.info(\"Generating confirmation message\")\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Generate a natural confirmation message for the event. Sign of with your name; Susie\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": str(event_details.model_dump())},\n",
    "        ],\n",
    "        response_format=EventConfirmation,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\"Confirmation message generated successfully\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Chain the functions together\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def process_calendar_request(user_input: str) -> Optional[EventConfirmation]:\n",
    "    \"\"\"Main function implementing the prompt chain with gate check\"\"\"\n",
    "    logger.info(\"Processing calendar request\")\n",
    "    logger.debug(f\"Raw input: {user_input}\")\n",
    "\n",
    "    # First LLM call: Extract basic info\n",
    "    initial_extraction = extract_event_info(user_input)\n",
    "\n",
    "    # Gate check: Verify if it's a calendar event with sufficient confidence\n",
    "    if (\n",
    "        not initial_extraction.is_calendar_event\n",
    "        or initial_extraction.confidence_score < 0.7\n",
    "    ):\n",
    "        logger.warning(\n",
    "            f\"Gate check failed - is_calendar_event: {initial_extraction.is_calendar_event}, confidence: {initial_extraction.confidence_score:.2f}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    logger.info(\"Gate check passed, proceeding with event processing\")\n",
    "\n",
    "    # Second LLM call: Get detailed event information\n",
    "    event_details = parse_event_details(initial_extraction.description)\n",
    "\n",
    "    # Third LLM call: Generate confirmation\n",
    "    confirmation = generate_confirmation(event_details)\n",
    "\n",
    "    logger.info(\"Calendar request processing completed successfully\")\n",
    "    return confirmation\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 4: Test the chain with a valid input\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "user_input = \"Let's schedule a 1h team meeting next Tuesday at 2pm with Alice and Bob to discuss the project roadmap.\"\n",
    "\n",
    "result = process_calendar_request(user_input)\n",
    "if result:\n",
    "    print(f\"Confirmation: {result.confirmation_message}\")\n",
    "    if result.calendar_link:\n",
    "        print(f\"Calendar Link: {result.calendar_link}\")\n",
    "else:\n",
    "    print(\"This doesn't appear to be a calendar event request.\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 5: Test the chain with an invalid input\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "user_input = \"Can you send an email to Alice and Bob to discuss the project roadmap?\"\n",
    "\n",
    "result = process_calendar_request(user_input)\n",
    "if result:\n",
    "    print(f\"Confirmation: {result.confirmation_message}\")\n",
    "    if result.calendar_link:\n",
    "        print(f\"Calendar Link: {result.calendar_link}\")\n",
    "else:\n",
    "    print(\"This doesn't appear to be a calendar event request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
