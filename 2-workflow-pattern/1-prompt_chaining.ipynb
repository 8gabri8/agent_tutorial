{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Chaining\n",
    "\n",
    "It is a specific pattern that to build an AI agent, i.e. how user prompt, llm reasoning and tools responses are linked otgether.\n",
    "\n",
    "Prompt chaining decomposes a task into a sequence of steps, where each LLM call processes the output of the previous one. You can add programmatic checks (see \"gate” in the diagram below) on any intermediate steps to ensure that the process is still on track.\n",
    "\n",
    "![assets/prompt-chaning.png][assets/prompt-chaning.pngdef]\n",
    "\n",
    "Tutorial: given as prompt a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging configuration\n",
    "\n",
    "logging.basicConfig( #logging module, which is used to record events and messages generated by a program\n",
    "    level=logging.INFO, #  only messages of level INFO and higher (INFO, WARNING, ERROR, CRITICAL) will be logged.\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\", # specifies the format of the log messages\n",
    "        # time-log level-message\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\", #format of the timestamp in the log messages\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilalize ollama api\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', \n",
    ")\n",
    "\n",
    "MODEL = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strucred data with pydantic\n",
    "\n",
    "class EventExtraction(BaseModel):\n",
    "    \"\"\"First LLM call: Extract basic event information\"\"\"\n",
    "\n",
    "    description: str = Field(description=\"Raw description of the event\")\n",
    "    is_calendar_event: bool = Field(description=\"Whether this text describes a calendar event\")\n",
    "    confidence_score: float = Field(description=\"Confidence score between 0 and 1\")\n",
    "\n",
    "\n",
    "class EventDetails(BaseModel):\n",
    "    \"\"\"Second LLM call: Parse specific event details\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the event\")\n",
    "    date: str = Field(description=\"Date and time of the event. Use ISO 8601 to format this value.\")\n",
    "    duration_minutes: int = Field(description=\"Expected duration in minutes\")\n",
    "    participants: list[str] = Field(description=\"List of participants\")\n",
    "\n",
    "\n",
    "class EventConfirmation(BaseModel):\n",
    "    \"\"\"Third LLM call: Generate confirmation message\"\"\"\n",
    "\n",
    "    confirmation_message: str = Field(description=\"Natural language confirmation message\")\n",
    "    calendar_link: Optional[str] = Field(description=\"Generated calendar link if applicable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 2: Define the functions\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_event_info(user_input: str) -> EventExtraction:\n",
    "    \"\"\"First LLM call to determine if input is a calendar event\"\"\"\n",
    "    logger.info(\"Starting event extraction analysis\")\n",
    "    logger.debug(f\"Input text: {user_input}\")\n",
    "\n",
    "    today = datetime.now()\n",
    "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{date_context} Analyze if the text describes a calendar event.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ],\n",
    "        response_format=EventExtraction,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\n",
    "        f\"Extraction complete - Is calendar event: {result.is_calendar_event}, Confidence: {result.confidence_score:.2f}\"\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_event_details(description: str) -> EventDetails:\n",
    "    \"\"\"Second LLM call to extract specific event details\"\"\"\n",
    "    logger.info(\"Starting event details parsing\")\n",
    "\n",
    "    today = datetime.now()\n",
    "    date_context = f\"Today is {today.strftime('%A, %B %d, %Y')}.\"\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"{date_context} Extract detailed event information. When dates reference 'next Tuesday' or similar relative dates, use this current date as reference.\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": description},\n",
    "        ],\n",
    "        response_format=EventDetails,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\n",
    "        f\"Parsed event details - Name: {result.name}, Date: {result.date}, Duration: {result.duration_minutes}min\"\n",
    "    )\n",
    "    logger.debug(f\"Participants: {', '.join(result.participants)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_confirmation(event_details: EventDetails) -> EventConfirmation:\n",
    "    \"\"\"Third LLM call to generate a confirmation message\"\"\"\n",
    "    logger.info(\"Generating confirmation message\")\n",
    "\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Generate a natural confirmation message for the event. Sign of with your name; Susie\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": str(event_details.model_dump())},\n",
    "        ],\n",
    "        response_format=EventConfirmation,\n",
    "    )\n",
    "    result = completion.choices[0].message.parsed\n",
    "    logger.info(\"Confirmation message generated successfully\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 3: Chain the functions together\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "\n",
    "def process_calendar_request(user_input: str) -> Optional[EventConfirmation]:\n",
    "    \"\"\"Main function implementing the prompt chain with gate check\"\"\"\n",
    "    logger.info(\"Processing calendar request\")\n",
    "    logger.debug(f\"Raw input: {user_input}\")\n",
    "\n",
    "    # First LLM call: Extract basic info\n",
    "    initial_extraction = extract_event_info(user_input)\n",
    "\n",
    "    # Gate check: Verify if it's a calendar event with sufficient confidence\n",
    "    if (\n",
    "        not initial_extraction.is_calendar_event\n",
    "        or initial_extraction.confidence_score < 0.7\n",
    "    ):\n",
    "        logger.warning(\n",
    "            f\"Gate check failed - is_calendar_event: {initial_extraction.is_calendar_event}, confidence: {initial_extraction.confidence_score:.2f}\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "    logger.info(\"Gate check passed, proceeding with event processing\")\n",
    "\n",
    "    # Second LLM call: Get detailed event information\n",
    "    event_details = parse_event_details(initial_extraction.description)\n",
    "\n",
    "    # Third LLM call: Generate confirmation\n",
    "    confirmation = generate_confirmation(event_details)\n",
    "\n",
    "    logger.info(\"Calendar request processing completed successfully\")\n",
    "    return confirmation\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 4: Test the chain with a valid input\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "user_input = \"Let's schedule a 1h team meeting next Tuesday at 2pm with Alice and Bob to discuss the project roadmap.\"\n",
    "\n",
    "result = process_calendar_request(user_input)\n",
    "if result:\n",
    "    print(f\"Confirmation: {result.confirmation_message}\")\n",
    "    if result.calendar_link:\n",
    "        print(f\"Calendar Link: {result.calendar_link}\")\n",
    "else:\n",
    "    print(\"This doesn't appear to be a calendar event request.\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Step 5: Test the chain with an invalid input\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "user_input = \"Can you send an email to Alice and Bob to discuss the project roadmap?\"\n",
    "\n",
    "result = process_calendar_request(user_input)\n",
    "if result:\n",
    "    print(f\"Confirmation: {result.confirmation_message}\")\n",
    "    if result.calendar_link:\n",
    "        print(f\"Calendar Link: {result.calendar_link}\")\n",
    "else:\n",
    "    print(\"This doesn't appear to be a calendar event request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
